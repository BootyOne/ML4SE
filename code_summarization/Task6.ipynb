{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Код был основан из [данного](https://github.com/microsoft/CodeBERT/tree/master/CodeBERT/code2nl) репозитория."
      ],
      "metadata": {
        "id": "sh9jSvj7Vemi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Beam:\n",
        "    def __init__(self, size, sos, eos, device):\n",
        "        self.size = size\n",
        "        if device == \"cuda\":\n",
        "            self.tt = torch.cuda\n",
        "        elif device == \"cpu\":\n",
        "            self.tt = torch\n",
        "        self.scores = self.tt.FloatTensor(size).zero_()\n",
        "        self.prevKs = []\n",
        "        self.nextYs = [self.tt.LongTensor(size).fill_(0)]\n",
        "        self.nextYs[0][0] = sos\n",
        "        self._eos = eos\n",
        "        self.eosTop = False\n",
        "        self.finished = []\n",
        "\n",
        "    def getCurrentState(self):\n",
        "        return self.tt.LongTensor(self.nextYs[-1]).view(-1, 1)\n",
        "\n",
        "    def getCurrentOrigin(self):\n",
        "        return self.prevKs[-1]\n",
        "\n",
        "    def advance(self, wordLk):\n",
        "        numWords = wordLk.size(1)\n",
        "        if len(self.prevKs) > 0:\n",
        "            beamLk = wordLk + self.scores.unsqueeze(1).expand_as(wordLk)\n",
        "            for i in range(self.nextYs[-1].size(0)):\n",
        "                if self.nextYs[-1][i] == self._eos:\n",
        "                    beamLk[i] = -1e20\n",
        "        else:\n",
        "            beamLk = wordLk[0]\n",
        "        flatBeamLk = beamLk.view(-1)\n",
        "        bestScores, bestScoresId = flatBeamLk.topk(self.size, 0, True, True)\n",
        "        self.scores = bestScores\n",
        "        prevK = bestScoresId // numWords\n",
        "        self.prevKs.append(prevK)\n",
        "        self.nextYs.append((bestScoresId - prevK * numWords))\n",
        "        for i in range(self.nextYs[-1].size(0)):\n",
        "            if self.nextYs[-1][i] == self._eos:\n",
        "                self.finished.append((self.scores[i], len(self.nextYs) - 1, i))\n",
        "        if self.nextYs[-1][0] == self._eos:\n",
        "            self.eosTop = True\n",
        "\n",
        "    def done(self):\n",
        "        return self.eosTop and len(self.finished) >= self.size\n",
        "\n",
        "    def getFinal(self):\n",
        "        if len(self.finished) == 0:\n",
        "            self.finished.append((self.scores[0], len(self.nextYs) - 1, 0))\n",
        "        self.finished.sort(key=lambda a: -a[0])\n",
        "        if len(self.finished) != self.size:\n",
        "            unfinished = []\n",
        "            for i in range(self.nextYs[-1].size(0)):\n",
        "                if self.nextYs[-1][i] != self._eos:\n",
        "                    s = self.scores[i]\n",
        "                    unfinished.append((s, len(self.nextYs) - 1, i))\n",
        "            unfinished.sort(key=lambda a: -a[0])\n",
        "            self.finished += unfinished[: self.size - len(self.finished)]\n",
        "        return self.finished[: self.size]\n",
        "\n",
        "    def getHyp(self, beam_res):\n",
        "        hyps = []\n",
        "        for _, timestep, k in beam_res:\n",
        "            hyp = []\n",
        "            for j in range(len(self.prevKs[:timestep]) - 1, -1, -1):\n",
        "                hyp.append(self.nextYs[j + 1][k])\n",
        "                k = self.prevKs[j][k]\n",
        "            hyps.append(hyp[::-1])\n",
        "        return hyps\n",
        "\n",
        "    def buildTargetTokens(self, preds):\n",
        "        sentence = []\n",
        "        for pred in preds:\n",
        "            tokens = []\n",
        "            for tok in pred:\n",
        "                if tok == self._eos:\n",
        "                    break\n",
        "                tokens.append(tok)\n",
        "            sentence.append(tokens)\n",
        "        return sentence\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, config, beam_size=None,\n",
        "        max_length=None, sos_id=None, eos_id=None):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.config = config\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(2048, 2048)))\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "        self.lsm = nn.LogSoftmax(dim=-1)\n",
        "        self.tie_weights()\n",
        "        self.beam_size = beam_size\n",
        "        self.max_length = max_length\n",
        "        self.sos_id = sos_id\n",
        "        self.eos_id = eos_id\n",
        "\n",
        "    def _tie_or_clone_weights(self, first_module, second_module):\n",
        "        if self.config.torchscript:\n",
        "            first_module.weight = nn.Parameter(second_module.weight.clone())\n",
        "        else:\n",
        "            first_module.weight = second_module.weight\n",
        "\n",
        "    def tie_weights(self):\n",
        "        self._tie_or_clone_weights(self.lm_head, self.encoder.embeddings.word_embeddings)\n",
        "\n",
        "    def forward(self, source_ids, source_mask):\n",
        "        outputs = self.encoder(source_ids, attention_mask=source_mask)\n",
        "        encoder_output = outputs[0].permute([1, 0, 2]).contiguous()\n",
        "        preds = []\n",
        "        if source_ids.device.type == \"cuda\":\n",
        "            zero = torch.cuda.LongTensor(1).fill_(0)\n",
        "        elif source_ids.device.type == \"cpu\":\n",
        "            zero = torch.LongTensor(1).fill_(0)\n",
        "        for i in range(source_ids.shape[0]):\n",
        "            beam = Beam(\n",
        "                self.beam_size,\n",
        "                self.sos_id,\n",
        "                self.eos_id,\n",
        "                device=source_ids.device.type,\n",
        "            )\n",
        "            context = encoder_output[:, i:i + 1].repeat(1, self.beam_size, 1)\n",
        "            context_mask = source_mask[i:i + 1, :].repeat(self.beam_size, 1)\n",
        "            input_ids = beam.getCurrentState()\n",
        "            for _ in range(self.max_length):\n",
        "                if beam.done():\n",
        "                    break\n",
        "                attn_mask = -1e4 * (1 - self.bias[:input_ids.shape[1], :input_ids.shape[1]])\n",
        "                tgt_embeddings = (\n",
        "                    self.encoder.embeddings(input_ids)\n",
        "                    .permute([1, 0, 2])\n",
        "                    .contiguous()\n",
        "                )\n",
        "                out = self.decoder(\n",
        "                    tgt_embeddings,\n",
        "                    context,\n",
        "                    tgt_mask=attn_mask,\n",
        "                    memory_key_padding_mask=(1 - context_mask).bool(),\n",
        "                )\n",
        "                out = torch.tanh(self.dense(out))\n",
        "                hidden_states = out.permute([1, 0, 2]).contiguous()[:, -1, :]\n",
        "                out = self.lsm(self.lm_head(hidden_states)).data\n",
        "                beam.advance(out)\n",
        "                input_ids.data.copy_(input_ids.data.index_select(0, beam.getCurrentOrigin()))\n",
        "                input_ids = torch.cat((input_ids, beam.getCurrentState()), -1)\n",
        "            hyp = beam.getHyp(beam.getFinal())\n",
        "            pred = beam.buildTargetTokens(hyp)[: self.beam_size]\n",
        "            pred = [torch.cat([x.view(-1) for x in p] + [zero] * (self.max_length - len(p))).view(1, -1) for p in pred]\n",
        "            preds.append(torch.cat(pred, 0).unsqueeze(0))\n",
        "        preds = torch.cat(preds, 0)\n",
        "        return preds"
      ],
      "metadata": {
        "id": "cD_UZM8jVqMp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://code-summary.s3.amazonaws.com/pytorch_model.bin"
      ],
      "metadata": {
        "id": "mPe1tnMpZDto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "\n",
        "\n",
        "class InputFeatures:\n",
        "    def __init__(self, example_id, source_ids,\n",
        "        target_ids, source_mask, target_mask):\n",
        "        self.example_id = example_id\n",
        "        self.source_ids = source_ids\n",
        "        self.target_ids = target_ids\n",
        "        self.source_mask = source_mask\n",
        "        self.target_mask = target_mask\n",
        "\n",
        "\n",
        "def convert_examples_to_features(examples, tokenizer):\n",
        "    features = []\n",
        "    for example_index, example in enumerate(examples):\n",
        "        source_tokens = tokenizer.tokenize(example)[: 256 - 2]\n",
        "        source_tokens = [tokenizer.cls_token] + source_tokens + [tokenizer.sep_token]\n",
        "        source_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
        "        source_mask = [1] * (len(source_tokens))\n",
        "        padding_length = 256 - len(source_ids)\n",
        "        source_ids += [tokenizer.pad_token_id] * padding_length\n",
        "        source_mask += [0] * padding_length\n",
        "        target_tokens = tokenizer.tokenize(\"None\")\n",
        "        target_tokens = [tokenizer.cls_token] + target_tokens + [tokenizer.sep_token]\n",
        "        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
        "        target_mask = [1] * len(target_ids)\n",
        "        padding_length = 128 - len(target_ids)\n",
        "        target_ids += [tokenizer.pad_token_id] * padding_length\n",
        "        target_mask += [0] * padding_length\n",
        "        features.append(InputFeatures(\n",
        "            example_index,\n",
        "            source_ids,\n",
        "            target_ids,\n",
        "            source_mask,\n",
        "            target_mask,\n",
        "            )\n",
        "        )\n",
        "    return features\n",
        "\n",
        "def conclusion(data, model, tokenizer):\n",
        "    eval_sampler = SequentialSampler(data)\n",
        "    eval_dataloader = DataLoader(data, sampler=eval_sampler, batch_size=len(data))\n",
        "    model.eval()\n",
        "    p = []\n",
        "    for batch in eval_dataloader:\n",
        "        batch = tuple(t.to('cpu') for t in batch)\n",
        "        source_ids, source_mask = batch\n",
        "        with torch.no_grad():\n",
        "            preds = model(source_ids=source_ids, source_mask=source_mask)\n",
        "            for pred in preds:\n",
        "                t = pred[0].cpu().numpy()\n",
        "                t = list(t)\n",
        "                if 0 in t:\n",
        "                    t = t[: t.index(0)]\n",
        "                text = tokenizer.decode(t, clean_up_tokenization_spaces=False)\n",
        "                p.append(text)\n",
        "    return p\n",
        "\n",
        "\n",
        "def get_feature(examples, tokenizer):\n",
        "    features = convert_examples_to_features(examples, tokenizer)\n",
        "    all_source_ids = torch.tensor([f.source_ids[: 256] for f in features], dtype=torch.long)\n",
        "    all_source_mask = torch.tensor([f.source_mask[: 256] for f in features], dtype=torch.long)\n",
        "    return TensorDataset(all_source_ids, all_source_mask)\n",
        "\n",
        "\n",
        "def get_model(model_class, config, tokenizer):\n",
        "    encoder = model_class(config=config)\n",
        "    decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
        "    decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
        "    model = Seq2Seq(\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "        config=config,\n",
        "        beam_size=10,\n",
        "        max_length=128,\n",
        "        sos_id=tokenizer.cls_token_id,\n",
        "        eos_id=tokenizer.sep_token_id,\n",
        "    )\n",
        "    model.load_state_dict(torch.load(\"pytorch_model.bin\", map_location=torch.device(\"cpu\")), strict=False)\n",
        "    return model"
      ],
      "metadata": {
        "id": "KL4yhHkMV6ID"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Y1axGWGKY3vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer\n",
        "\n",
        "\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "config = RobertaConfig.from_pretrained(model_name)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
        "model = get_model(model_class=RobertaModel, config=config, tokenizer=tokenizer).to('cpu')\n",
        "\n",
        "def estimate(example):\n",
        "    return conclusion(get_feature([example], tokenizer), model, tokenizer)\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def is_digit(obj):\n",
        "    return obj.isdigit()\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def is_digit(a):\n",
        "    return a.isdigit()\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def is_digit(obj):\n",
        "    if int(obj) == 0:\n",
        "        return True\n",
        "    elif int(obj) == 1:\n",
        "        return True\n",
        "    elif int(obj) == 2:\n",
        "        return True\n",
        "    elif int(obj) == 3:\n",
        "        return True\n",
        "    elif int(obj) == 4:\n",
        "        return True\n",
        "    elif int(obj) == 5:\n",
        "        return True\n",
        "    elif int(obj) == 6:\n",
        "        return True\n",
        "    elif int(obj) == 7:\n",
        "        return True\n",
        "    elif int(obj) == 8:\n",
        "        return True\n",
        "    elif int(obj) == 9:\n",
        "        return True\n",
        "    return False\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def is_digit(obj):\n",
        "    if int(obj) == 0 or int(obj) == 1 or int(obj) == 2 or int(obj) == 3 or int(obj) == 4 or int(obj) == 5 or int(obj) == 6 or int(obj) == 7 or int(obj) == 8 or int(obj) == 9:\n",
        "        return True\n",
        "    return False\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def check_if_an_object_is_a_digit(obj):\n",
        "    return obj.isdigit()\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def check_if_an_object_is_a_str(bj):\n",
        "    return obj.isdigit()\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def f(obj):\n",
        "    return obj.isdigit()\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def is_number(obj):\n",
        "    try:\n",
        "        int(obj)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def foo():\n",
        "    pass\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def fib(number):\n",
        "    fib1 = 1\n",
        "    fib2 = 1\n",
        "\n",
        "    i = 0\n",
        "    while i < number - 2:\n",
        "        fib_sum = fib1 + fib2\n",
        "        fib1 = fib2\n",
        "        fib2 = fib_sum\n",
        "        i = i + 1\n",
        "\n",
        "    return fib2\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def fib(number):\n",
        "    fib1 = fib2 = 1\n",
        "    number -= 2\n",
        "\n",
        "    while number > 0:\n",
        "        fib1, fib2 = fib2, fib1 + fib2\n",
        "        number -= 1\n",
        "\n",
        "    return fib2\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def fibonacci(n):\n",
        "    if n in (1, 2):\n",
        "        return 1\n",
        "    return fibonacci(n - 1) + fibonacci(n - 2)\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def some_function(n):\n",
        "    a = b = 1\n",
        "    n -= 2\n",
        "\n",
        "    while n > 0:\n",
        "        a, b = b, a + b\n",
        "        n -= 1\n",
        "\n",
        "    return b\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def quicksort(nums, fst, lst):\n",
        "   if fst >= lst: return\n",
        " \n",
        "   i, j = fst, lst\n",
        "   pivot = nums[random.randint(fst, lst)]\n",
        " \n",
        "   while i <= j:\n",
        "       while nums[i] < pivot: i += 1\n",
        "       while nums[j] > pivot: j -= 1\n",
        "       if i <= j:\n",
        "           nums[i], nums[j] = nums[j], nums[i]\n",
        "           i, j = i + 1, j - 1\n",
        "   quicksort(nums, fst, j)\n",
        "   quicksort(nums, i, lst)\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def bSort(array):\n",
        "    # определяем длину массива\n",
        "    length = len(array)\n",
        "    #Внешний цикл, количество проходов N-1\n",
        "    for i in range(length):\n",
        "        # Внутренний цикл, N-i-1 проходов\n",
        "        for j in range(0, length-i-1):\n",
        "            #Меняем элементы местами\n",
        "            if array[j] > array[j+1]:\n",
        "                temp = array[j]\n",
        "                array[j] = array[j+1]\n",
        "                array[j+1] = temp\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def bSort(array):\n",
        "    length = len(array)\n",
        "    for i in range(length):\n",
        "        for j in range(0, length-i-1):\n",
        "            if array[j] > array[j+1]:\n",
        "                temp = array[j]\n",
        "                array[j] = array[j+1]\n",
        "                array[j+1] = temp\n",
        "\"\"\"))\n",
        "\n",
        "print(estimate(\"\"\"\n",
        "def binary_search_iterative(array, element):\n",
        "    mid = 0\n",
        "    start = 0\n",
        "    end = len(array)\n",
        "    step = 0\n",
        "\n",
        "    while (start <= end):\n",
        "        print(\"Subarray in step {}: {}\".format(step, str(array[start:end+1])))\n",
        "        step = step+1\n",
        "        mid = (start + end) // 2\n",
        "\n",
        "        if element == array[mid]:\n",
        "            return mid\n",
        "\n",
        "        if element < array[mid]:\n",
        "            end = mid - 1\n",
        "        else:\n",
        "            start = mid + 1\n",
        "    return -1\n",
        "\"\"\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4iZty46WAP8",
        "outputId": "0d46b2e3-aa26-48a8-ebf8-d3233e6291f8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Check if obj is a digit .']\n",
            "['Check if a string is a digit .']\n",
            "['Check if an integer is a valid digit .']\n",
            "['Check if an object is a valid digit']\n",
            "['Check if an object is a digit .']\n",
            "['Check if the object is a string']\n",
            "['Return boolean value .']\n",
            "['Check if an object is a number']\n",
            "['This function is called every time .']\n",
            "['Fulfillacci function']\n",
            "['Fulfillacci fib1 .']\n",
            "[' fibonacci number']\n",
            "['wrapper around n times']\n",
            "['Sort a list of numbers in fst .']\n",
            "['BSort function .']\n",
            "['Sort an array .']\n",
            "['Binary search method .']\n"
          ]
        }
      ]
    }
  ]
}